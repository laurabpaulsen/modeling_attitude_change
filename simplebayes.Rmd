---
title: "bayesian models of cognition"
author: "Laura Bock Paulsen"
date: "2024-03-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

pacman::p_load(tidyverse,
        here,
        posterior,
        cmdstanr,
        brms, tidybayes)

```


# Simple bayes
## Defining functions for simple bayes
```{r}
simple_bayes_beta_binomial <- function(source1, source2, inverse_temperature=1, lower_bound=1, upper_bound= 8){
  n_rows = length(source1)
  # calculate alpha for beta distribution
  alpha <- inverse_temperature * (source1 + source2 - 2 * lower_bound)
  
  # calculating beta for the beta distribution
  beta <- inverse_temperature * (2 * (upper_bound - lower_bound)) - alpha
  
  # sample from a beta distribution
  belief <- rbeta(n_rows, alpha, beta)
  
  # predict the rating
  second_rating <- lower_bound + rbinom(n_rows, upper_bound - lower_bound, belief)

  return(second_rating)
}
```



```{r}
# turning the belief into a choice that is either 1, 2, 3, 4, 5, 6, 7, 8

## SUGGESTIONS ##
# ordered regression stan user guide
# logit of belief between zero and one and model it as a normal distribution
    # MAKE SURE TO CHECK WHAT HAPPENS WHEN LOGIT TRANSFORMING the numbers coming out of the simple bayes
  # maybe change the ratings
  # implicitly modelling it as trying to decide whether the face is trustworthy or not
    # that is source1 = 6, source2 = 6 will lead to a score of maybe 7 
# modelling it as a binomial with 8 tries

source1 <- seq(1, 8, 1)
source2 <- seq(1, 8, 1)
n_trials <- seq(1, 100, 1)


df <- expand.grid("trials" = n_trials, "source1" = source1, "source2" = source2)


# BETA BINOMIAL IMPLEMENTATION
df$second_rating_beta_binomial <- simple_bayes_beta_binomial(df$source1, df$source2)
```


```{r}
data <- read_csv("data/Simonsen_clean.csv")

# data from only one partipant for testing
data <- data |>
  filter(ID == sample(unique(ID), 1))

# make a matrices with shape n_trials and n_subjects for first rating, group rating and second rating
unique_subjects <- unique(data$ID)

# initialize matrices to store ratings
n_subjects <- length(unique_subjects)
n_trials <- 153

first_rating_matrix <- matrix(NA, nrow = n_trials, ncol = n_subjects)
group_rating_matrix <- matrix(NA, nrow = n_trials, ncol = n_subjects)
second_rating_matrix <- matrix(NA, nrow = n_trials, ncol = n_subjects)

# Fill in the matrices with ratings
for (i in 1:length(unique_subjects)) {
  subject_data <- data[data$ID == unique_subjects[i], ]
  first_rating_matrix[, i] <- subject_data$FirstRating
  group_rating_matrix[, i] <- subject_data$GroupRating
  second_rating_matrix[, i] <- subject_data$SecondRating
}


```



```{r}
simple_betabayes <- cmdstan_model("simple_bayes_betabinomial.stan")

fit_simple <- simple_betabayes$sample(
  data = list(N = n_trials,
              N_subj = n_subjects,
              lower_bound = 1,
              upper_bound = 8,
              first_rating = first_rating_matrix,
              group_rating = group_rating_matrix,
              second_rating = second_rating_matrix
              )
  )
```

```{r}
fit_simple$summary()
fit_simple$cmdstan_diagnose()
fit_simple$loo()
```

```{r}
draws_df <- as_draws_df(fit_simple$draws())

ggplot(draws_df, aes(.iteration, posterior_invtemp, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()
```
```{r}
ggplot(draws_df, aes(posterior_invtemp)) +
  geom_density(aes(posterior_invtemp), col = "blue") +
  geom_density(aes(prior_invtemp)) + 
  xlim(0, 10) + 
  theme_bw()
```


# Weighted bayes
## Functions for weighted bayes
```{r}
weighted_bayes_beta_binomial <- function(source1, source2, weight1, weight2, inverse_temperature=1, lower_bound=1, upper_bound= 8){
  n_rows = length(source1)
  # calculate alpha for beta distribution

  # NOTE: check course notes, riccardo does something where he scales the weights??
  ## From course notes  w1 <- (w1 - 0.5)*2 and w2 <- (w2 - 0.5)*2
  alpha <- inverse_temperature * (weight1 * source1 + weight2 * source2 - 2 * lower_bound)
  
  # calculating beta for the beta distribution
  beta <- inverse_temperature * (2 * (upper_bound - lower_bound)) - alpha
  
  # sample from a beta distribution
  belief <- rbeta(n_rows, alpha, beta)
  
  # predict the rating
  second_rating <- lower_bound + rbinom(n_rows, upper_bound - lower_bound, belief)

  return(second_rating)
}
```




# Model comparison

```{r}
# compare fit_simple and fit_weighted
```


## Code trashcan
```{r}
# maybe think about changing this to account better for the fact that these ratings are going to be used on the logit scale, which makes the distance between each rating unpropropotional
convert_ratings <- function(value, max_val=8){
  return((value) /(max_val+1))
}

simple_bayes <- function(source1, source2){
  belief <- inv_logit_scaled(0.5*logit_scaled(source1) + 0.5*logit_scaled(source2)) # 0.5 to get the average between the two sources 
  
  return(belief)
}


df$belief <- simple_bayes(convert_ratings(df$source1), convert_ratings(df$source2))

# LOGIT IMPLEMENTATION
df$second_rating <- round(df$belief * 10-1)

# is this to hacky???
df$second_rating <- ifelse(df$second_rating < 1, 1, 
                           ifelse(df$second_rating > 8, 8, df$second_rating))

```


